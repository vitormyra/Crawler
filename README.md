# JAC.WebCrawling


este exemplo pratico sobre o WebCrawling, que tem se tornado cada vez mais util para os programadores,estarei usando
[] - 
HtmlAgilityPack
Net.Http

O que é o rastreio da Web?
Crawling é o processo em virtude do qual os motores de busca coletam informações sobre sites na world wide web. Ele também pode ser usado para automatizar tarefas de manutenção em um site, como verificar links ou validar código HTML

Rastejar basicamente significa seguir um caminho. É por isso que muitos desenvolvedores de sites fornecem um mapa do site para facilitar a navegação e o rastreamento em seus sites.

Como os mecanismos de busca recomendam algumas páginas dos trilhões que existem? A resposta é o rastreamento da web

O que é um rastreador da Web?
Um rastreador da Web também conhecido como web spider ou webrobot é um programa ou script automatizado que navega na World Wide Web de maneira metodológica e automatizada. Esse processo é chamado de rastreamento da Web ou Spidering. Muitos sites legítimos, em particular os mecanismos de pesquisa, usam o Spidering como um meio de fornecer dados atualizados para análises.

Os rastreadores da Web são programas de computador que examinam a Web, "lêem" tudo o que encontram. Os rastreadores da Web também são conhecidos como spiders, bots e indexadores automáticos. Esses rastreadores verificam as páginas da Web para ver quais palavras elas contêm e onde essas palavras são usadas. O rastreador transforma suas descobertas em um índice gigante

A finalidade do rastreamento da Web é tipicamente para fins de indexação da Web ( spidering da Web ).

Web Indexing
Web Indexing refere-se a vários métodos para indexar o conteúdo de um site ou da Internet como um todo. O índice é basicamente uma grande lista de palavras e as páginas da Web que as apresentam. Os rastreadores da Web verificam a Web regularmente para que sempre tenham um índice atualizado da web. Então, quando você solicita a um site de busca por páginas sobre hipopótamos, o mecanismo de pesquisa verifica seu índice e fornece uma lista de páginas que mencionam hipopótamos.

Quando o Google visita seu site para fins de rastreamento. Esse processo é feito pelo rastreador do Google Spider e após o rastreamento ter sido feito, os resultados são colocados no índice do Google (ou seja, na pesquisa na Web)

Algumas ferramentas de rastreamento da Web para diferentes plataformas
Nutch
Escamoso
GRUB
Ccrawler
Opese
Googlebot
Arachnode.net
JSpider
Arale
WebLech
depois de toda a introdução ao que o web crawling é, vamos agora entrar na codificação real usando c # e visual studio 2013 seguindo estes passos. lembre-se que para este tutorial nós iremos obter os modelos de carro, link, URL da imagem e preços, mas depois de dominar este processo você pode obter qualquer informação em qualquer site, desde que eles estejam disponíveis no site, mas se você tiver algum desafio chegar até mim para que possamos olhar juntos.

